from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import StrOutputParser

from src.domain.state import GraphState
from src.domain.guardrails_check import HallucinationGrade, InputGuardrail, RetrievalGrader
from src.infrastructure.llm_factory import LLMFactory
from src.utils.logging import get_logger

logger = get_logger()

class RAGNodes:
    def __init__(self, retriever):
        self.retriever = retriever
        self.llm = LLMFactory.get_llm()
        self.grader_chain = self._build_grader_chain()
        self.rag_chain = self._build_rag_chain()
        self.rewriter_chain = self._build_rewriter_chain()
        self.guardrail_chain = self._build_guardrail_chain()
        self.hallucination_chain = self._build_hallucination_chain()

    def _build_hallucination_chain(self):
        llm_structured = self.llm.with_structured_output(HallucinationGrade, method="function_calling")
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um avaliador de alucina√ß√µes para um assistente de IA.
            Sua tarefa √© verificar se a RESPOSTA gerada √© baseada e apoiada pelos DOCUMENTOS fornecidos.
            
            Regras:
            - Se a resposta contiver informa√ß√µes que N√ÉO est√£o nos documentos: Responda 'nao' (alucina√ß√£o).
            - Se a resposta for fiel aos documentos: Responda 'sim' (ancorada/grounded).
            - N√£o julgue se a resposta √© verdadeira no mundo real, apenas se ela √© suportada pelo texto fornecido.
            """),
            ("human", "Documentos (Fatos):\n{documents}\n\nResposta Gerada:\n{generation}")
        ])
        return prompt | llm_structured

    def _build_grader_chain(self):
        llm_structured = self.llm.with_structured_output(RetrievalGrader, method="function_calling")
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um especialista em avaliar relev√¢ncia de documentos. 
Sua tarefa √© determinar se um documento recuperado responde ou √© relevante para a pergunta do usu√°rio.

Crit√©rios de relev√¢ncia:
- O documento cont√©m informa√ß√µes sobre o t√≥pico?
- O documento pode ajudar a responder a pergunta?
- Existe qualquer conex√£o tem√°tica?

Responda 'sim' se houver qualquer relev√¢ncia, 'nao' apenas se for completamente irrelevante."""),
            ("human", "Pergunta: {question}\n\nDocumento recuperado:\n{document}\n\nEste documento √© relevante para a pergunta? Responda 'sim' ou 'nao'.")
        ])
        return prompt | llm_structured

    def _build_rag_chain(self):
        prompt = PromptTemplate(
            template="""Voc√™ √© um especialista em Machado de Assis. Use o contexto: {context} 
            para responder √† pergunta: {question}.""",
            input_variables=["context", "question"]
        )
        return prompt | self.llm | StrOutputParser()

    def _build_rewriter_chain(self):
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um especialista em reformular perguntas sobre "Dom Casmurro" de Machado de Assis.
Sua tarefa √© reescrever a pergunta do usu√°rio mantendo seu significado ORIGINAL, mas usando terminologia e contexto do livro.

Dicas:
- Mantenha o sentido original da pergunta
- Use nomes de personagens, temas e conceitos do livro quando apropriado
- Reescreva de forma mais clara e espec√≠fica para melhorar a busca
- N√£o mude a inten√ß√£o da pergunta, apenas refine-a

Pergunta original: {original_question}

Reescreva de forma mais clara e espec√≠fica para busca sobre o livro:"""),
            ("human", "{question}")
        ])
        return prompt | self.llm | StrOutputParser()

    def _build_guardrail_chain(self):
        llm_structured = self.llm.with_structured_output(InputGuardrail, method="function_calling")
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Voc√™ √© um guardi√£o de conhecimento sobre o livro 'Dom Casmurro' de Machado de Assis.
            Sua fun√ß√£o √© filtrar perguntas que contenham premissas falsas, erros factuais graves ou que sejam sobre outros livros/assuntos.
            
            Exemplos de REJEI√á√ÉO:
            - "Quem √© Bento Santiago em Dom Casmurro?" (Correto)
            - "Quem √© Capitu?" (Correto, personagem de Dom Casmurro)
            - "Qual √© o tema de Dom Casmurro?" (Correto)
            - "Qual a receita de bolo de cenoura?" (Fora do contexto)
            
            Exemplos de APROVA√á√ÉO:
            - "Quem foi Virg√≠lia?"
            - "Por que ele dedicou o livro ao verme?"
            
            Analise a pergunta e determine se ela √© v√°lida para processamento.
            Analise se a pergunta √© v√°lida (sobre o livro, sem erros factuais graves).
    
            Retorne:
                - is_valid: true se a pergunta √© v√°lida, false caso contr√°rio
                - binary_score: 'sim' se v√°lida, 'n√£o' se inv√°lida
                - reason: explica√ß√£o breve se rejeitada
            
            """),
            ("human", "Pergunta: {question}")
        ])
        return prompt | llm_structured

    def validate_generation(self, state: GraphState):
        logger.debug("üîç Verificando alucina√ß√µes (Output Guardrail)...")
        question = state["question"]
        documents = state["documents"]
        generation = state["generation"]

        try:
            context_text = "\n\n".join([d.page_content for d in documents])
            
            score = self.hallucination_chain.invoke({
                "documents": context_text,
                "generation": generation
            })
            
            is_grounded = score.binary_score.lower() == "sim"
            
            if is_grounded:
                logger.info("‚úÖ Resposta validada: Fiel ao contexto.")
                return {"generation": generation, "hallucination": False}
            else:
                logger.warning(f"‚ö†Ô∏è Alucina√ß√£o detectada: {score.reason}")
                return {"generation": generation, "hallucination": True}
                
        except Exception as e:
            logger.error(f"Erro na valida√ß√£o de alucina√ß√£o: {e}")
            return {"generation": generation, "hallucination": False}
  
    def retrieve(self, state: GraphState):
        logger.debug(f"Buscando documentos para: {state['question'][:500]}...")
        documents = self.retriever.invoke(state["question"])
        logger.info(f"Recuperados {len(documents)} documentos")
        return {"documents": documents, "question": state["question"]}

    def grade_documents(self, state: GraphState):
        logger.debug("Avaliando relev√¢ncia dos documentos...")
        question = state["question"]
        documents = state["documents"]
        
        relevant_docs = []
        for i, doc in enumerate(documents):
            logger.debug(f"Avaliando documento {i+1}/{len(documents)}")
            try:
                score = self.grader_chain.invoke({
                    "question": question, 
                    "document": doc.page_content
                })
                is_relevant = score.binary_score.lower() == "sim"
                logger.debug(f"Documento {i+1}: {'RELEVANTE' if is_relevant else 'N√ÉO RELEVANTE'}")
                
                if is_relevant:
                    relevant_docs.append(doc)
            except Exception as e:
                logger.warning(f"Erro ao avaliar documento {i+1}: {e}")
        
        logger.info(f"Documentos relevantes: {len(relevant_docs)}/{len(documents)}")
        return {"documents": relevant_docs, "question": question}

    def generate(self, state: GraphState):
        logger.debug("Gerando resposta...")
        context_text = "\n\n".join([d.page_content for d in state["documents"]])
        
        generation = self.rag_chain.invoke({
            "context": context_text, 
            "question": state["question"]
        })
        
        logger.info("Resposta gerada com sucesso")
        return {"generation": generation}

    def transform_query(self, state: GraphState):
        logger.debug(f"Reescrevendo pergunta (tentativa {state.get('loop_count', 0) + 1})")
        original_question = state.get("original_question", state["question"])
        new_q = self.rewriter_chain.invoke({
            "original_question": original_question,
            "question": state["question"]
        })
        logger.info(f"Pergunta reescrita: \n {new_q[:500]}...")
        return {"question": new_q, "loop_count": state.get("loop_count", 0) + 1}

    def guardrails_check(self, state: GraphState):
        logger.debug("üõ°Ô∏è Verificando Guardrails da pergunta...")
        question = state["question"]
        
        try:
            outcome = self.guardrail_chain.invoke({"question": question})
            
            if outcome.is_valid:
                logger.info("‚úÖ Pergunta aprovada pelo Guardrail.")
                return {"question": question, "generation": None}
            else:
                logger.warning(f"‚õî Pergunta bloqueada: {outcome.reason}")
                return {
                    "question": question, 
                    "generation": f"N√£o posso responder a isso. {outcome.reason}"
                }
                
        except Exception as e:
            logger.error(f"Erro no guardrail: {e}")
            return {"question": question}